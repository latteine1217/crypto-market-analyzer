# 模型比較報告：XGBoost vs LSTM

## 1. 測試集性能比較

| 指標 | XGBoost | LSTM | 優勢模型 |
|------|---------|------|---------|
| RMSE | 253.96 | 662.59 | XGBoost ✓ |
| MAE | 179.85 | 505.44 | XGBoost ✓ |
| R² | 0.999270 | 0.988256 | XGBoost ✓ |
| MAPE | 0.185% | 0.550% | XGBoost ✓ |
| 方向準確率 | 86.43% | 47.41% | XGBoost ✓ |

## 2. 詳細分析

### 2.1 預測誤差分析

**XGBoost:**
- RMSE: 253.96 USDT
- MAE: 179.85 USDT
- MAPE: 0.185%

**LSTM:**
- RMSE: 662.59 USDT
- MAE: 505.44 USDT
- MAPE: 0.550%

**性能差距:**
- RMSE: XGBoost 優於 LSTM 2.61x
- MAE: XGBoost 優於 LSTM 2.81x
- MAPE: XGBoost 優於 LSTM 2.97x

### 2.2 預測準確性

**R² 分數:**
- XGBoost: 0.999270 （非常接近完美預測）
- LSTM: 0.988256 （優秀）

**方向準確率:**
- XGBoost: 86.43% （優秀）
- LSTM: 47.41% （幾乎隨機）

### 2.3 模型配置差異

**XGBoost:**
- 特徵數量: 84 個
- 樹數量: 200
- 最大深度: 8
- 學習率: 0.05
- 訓練集/測試集: 80/20

**LSTM:**
- 特徵數量: 6 個（僅使用可用的重要特徵）
- 序列長度: 30
- 隱藏層大小: 32
- 層數: 1
- 訓練集/驗證集/測試集: 70/15/15

## 3. 結論

### ✅ XGBoost 優勢

1. **預測精度更高**：
   - RMSE 低 2.61x
   - R² 接近完美 (0.9993)

2. **方向預測更準確**：
   - 方向準確率達 86.43%
   - 適合用於交易策略信號生成

3. **特徵利用更充分**：
   - 使用完整的 84 個特徵
   - 能夠捕捉複雜的特徵交互

### ⚠️ LSTM 劣勢

1. **預測誤差較大**：
   - 所有誤差指標均顯著高於 XGBoost

2. **方向預測幾乎隨機**：
   - 方向準確率僅 47.41%（接近 50%）
   - 不適合用於交易決策

3. **特徵使用受限**：
   - 僅使用 6 個特徵（缺失 rolling、lag 等關鍵特徵）
   - 可能限制了模型性能

### 💡 改進建議

**LSTM 模型改進方向：**

1. **增加特徵：**
   - 補充缺失的 rolling 特徵（rolling_mean, rolling_max, rolling_min）
   - 添加 lag 特徵
   - 達到與 XGBoost 相同的特徵覆蓋度

2. **調整架構：**
   - 增加隱藏層大小（32 → 64/128）
   - 添加更多 LSTM 層（1 → 2/3）
   - 嘗試 Bidirectional LSTM

3. **優化超參數：**
   - 調整序列長度（30 → 60/90）
   - 嘗試不同的學習率
   - 增加 dropout 以防止過擬合

4. **特徵工程：**
   - 對 LSTM 使用價格差分而非絕對價格
   - 添加技術指標的衍生特徵
   - 嘗試多變量時間序列輸入

## 4. 最終建議

**當前情況下，建議使用 XGBoost 模型：**

- 預測精度更高
- 方向準確率更好
- 適合生產環境部署
- 訓練和推理速度快

**未來可以考慮：**

1. 改進 LSTM 特徵工程後重新評估
2. 嘗試集成學習（XGBoost + LSTM）
3. 探索其他深度學習架構（Transformer、GRU）
