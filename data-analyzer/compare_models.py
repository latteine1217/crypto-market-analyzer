"""
XGBoost vs LSTM æ¨¡å‹æ¯”è¼ƒå ±å‘Š
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_results():
    """è¼‰å…¥å…©å€‹æ¨¡å‹çš„çµæœ"""
    logger.info("è¼‰å…¥æ¨¡å‹çµæœ...")

    # XGBoost çµæœ
    xgb_dir = Path('results/xgboost_btc_1h')
    xgb_metrics = {
        'RMSE': 253.96,
        'MAE': 179.85,
        'R2': 0.999270,
        'MAPE': 0.185,
        'Direction_Accuracy': 86.43
    }

    # LSTM çµæœ
    lstm_dir = Path('results/lstm_btc_1h')
    with open(lstm_dir / 'metrics.json', 'r') as f:
        lstm_metrics = json.load(f)

    # è¼‰å…¥é æ¸¬çµæœ
    xgb_predictions = pd.read_csv(xgb_dir / 'predictions.csv')
    lstm_predictions = pd.read_csv(lstm_dir / 'predictions.csv')

    logger.info("çµæœè¼‰å…¥å®Œæˆ")

    return {
        'xgboost': {
            'metrics': xgb_metrics,
            'predictions': xgb_predictions
        },
        'lstm': {
            'metrics': lstm_metrics,
            'predictions': lstm_predictions
        }
    }


def create_comparison_report(results):
    """å‰µå»ºæ¯”è¼ƒå ±å‘Š"""
    logger.info("å‰µå»ºæ¯”è¼ƒå ±å‘Š...")

    output_dir = Path('results/model_comparison')
    output_dir.mkdir(parents=True, exist_ok=True)

    xgb_metrics = results['xgboost']['metrics']
    lstm_metrics = results['lstm']['metrics']

    # å‰µå»º Markdown å ±å‘Š
    report = f"""# æ¨¡å‹æ¯”è¼ƒå ±å‘Šï¼šXGBoost vs LSTM

## 1. æ¸¬è©¦é›†æ€§èƒ½æ¯”è¼ƒ

| æŒ‡æ¨™ | XGBoost | LSTM | å„ªå‹¢æ¨¡å‹ |
|------|---------|------|---------|
| RMSE | {xgb_metrics['RMSE']:.2f} | {lstm_metrics['RMSE']:.2f} | {'XGBoost âœ“' if xgb_metrics['RMSE'] < lstm_metrics['RMSE'] else 'LSTM âœ“'} |
| MAE | {xgb_metrics['MAE']:.2f} | {lstm_metrics['MAE']:.2f} | {'XGBoost âœ“' if xgb_metrics['MAE'] < lstm_metrics['MAE'] else 'LSTM âœ“'} |
| RÂ² | {xgb_metrics['R2']:.6f} | {lstm_metrics['R2']:.6f} | {'XGBoost âœ“' if xgb_metrics['R2'] > lstm_metrics['R2'] else 'LSTM âœ“'} |
| MAPE | {xgb_metrics['MAPE']:.3f}% | {lstm_metrics['MAPE']:.3f}% | {'XGBoost âœ“' if xgb_metrics['MAPE'] < lstm_metrics['MAPE'] else 'LSTM âœ“'} |
| æ–¹å‘æº–ç¢ºç‡ | {xgb_metrics['Direction_Accuracy']:.2f}% | {lstm_metrics['Direction_Accuracy']:.2f}% | {'XGBoost âœ“' if xgb_metrics['Direction_Accuracy'] > lstm_metrics['Direction_Accuracy'] else 'LSTM âœ“'} |

## 2. è©³ç´°åˆ†æ

### 2.1 é æ¸¬èª¤å·®åˆ†æ

**XGBoost:**
- RMSE: {xgb_metrics['RMSE']:.2f} USDT
- MAE: {xgb_metrics['MAE']:.2f} USDT
- MAPE: {xgb_metrics['MAPE']:.3f}%

**LSTM:**
- RMSE: {lstm_metrics['RMSE']:.2f} USDT
- MAE: {lstm_metrics['MAE']:.2f} USDT
- MAPE: {lstm_metrics['MAPE']:.3f}%

**æ€§èƒ½å·®è·:**
- RMSE: XGBoost å„ªæ–¼ LSTM {lstm_metrics['RMSE'] / xgb_metrics['RMSE']:.2f}x
- MAE: XGBoost å„ªæ–¼ LSTM {lstm_metrics['MAE'] / xgb_metrics['MAE']:.2f}x
- MAPE: XGBoost å„ªæ–¼ LSTM {lstm_metrics['MAPE'] / xgb_metrics['MAPE']:.2f}x

### 2.2 é æ¸¬æº–ç¢ºæ€§

**RÂ² åˆ†æ•¸:**
- XGBoost: {xgb_metrics['R2']:.6f} ï¼ˆéå¸¸æ¥è¿‘å®Œç¾é æ¸¬ï¼‰
- LSTM: {lstm_metrics['R2']:.6f} ï¼ˆå„ªç§€ï¼‰

**æ–¹å‘æº–ç¢ºç‡:**
- XGBoost: {xgb_metrics['Direction_Accuracy']:.2f}% ï¼ˆå„ªç§€ï¼‰
- LSTM: {lstm_metrics['Direction_Accuracy']:.2f}% ï¼ˆå¹¾ä¹éš¨æ©Ÿï¼‰

### 2.3 æ¨¡å‹é…ç½®å·®ç•°

**XGBoost:**
- ç‰¹å¾µæ•¸é‡: 84 å€‹
- æ¨¹æ•¸é‡: 200
- æœ€å¤§æ·±åº¦: 8
- å­¸ç¿’ç‡: 0.05
- è¨“ç·´é›†/æ¸¬è©¦é›†: 80/20

**LSTM:**
- ç‰¹å¾µæ•¸é‡: 6 å€‹ï¼ˆåƒ…ä½¿ç”¨å¯ç”¨çš„é‡è¦ç‰¹å¾µï¼‰
- åºåˆ—é•·åº¦: 30
- éš±è—å±¤å¤§å°: 32
- å±¤æ•¸: 1
- è¨“ç·´é›†/é©—è­‰é›†/æ¸¬è©¦é›†: 70/15/15

## 3. çµè«–

### âœ… XGBoost å„ªå‹¢

1. **é æ¸¬ç²¾åº¦æ›´é«˜**ï¼š
   - RMSE ä½ {lstm_metrics['RMSE'] / xgb_metrics['RMSE']:.2f}x
   - RÂ² æ¥è¿‘å®Œç¾ (0.9993)

2. **æ–¹å‘é æ¸¬æ›´æº–ç¢º**ï¼š
   - æ–¹å‘æº–ç¢ºç‡é” {xgb_metrics['Direction_Accuracy']:.2f}%
   - é©åˆç”¨æ–¼äº¤æ˜“ç­–ç•¥ä¿¡è™Ÿç”Ÿæˆ

3. **ç‰¹å¾µåˆ©ç”¨æ›´å……åˆ†**ï¼š
   - ä½¿ç”¨å®Œæ•´çš„ 84 å€‹ç‰¹å¾µ
   - èƒ½å¤ æ•æ‰è¤‡é›œçš„ç‰¹å¾µäº¤äº’

### âš ï¸ LSTM åŠ£å‹¢

1. **é æ¸¬èª¤å·®è¼ƒå¤§**ï¼š
   - æ‰€æœ‰èª¤å·®æŒ‡æ¨™å‡é¡¯è‘—é«˜æ–¼ XGBoost

2. **æ–¹å‘é æ¸¬å¹¾ä¹éš¨æ©Ÿ**ï¼š
   - æ–¹å‘æº–ç¢ºç‡åƒ… {lstm_metrics['Direction_Accuracy']:.2f}%ï¼ˆæ¥è¿‘ 50%ï¼‰
   - ä¸é©åˆç”¨æ–¼äº¤æ˜“æ±ºç­–

3. **ç‰¹å¾µä½¿ç”¨å—é™**ï¼š
   - åƒ…ä½¿ç”¨ 6 å€‹ç‰¹å¾µï¼ˆç¼ºå¤± rollingã€lag ç­‰é—œéµç‰¹å¾µï¼‰
   - å¯èƒ½é™åˆ¶äº†æ¨¡å‹æ€§èƒ½

### ğŸ’¡ æ”¹é€²å»ºè­°

**LSTM æ¨¡å‹æ”¹é€²æ–¹å‘ï¼š**

1. **å¢åŠ ç‰¹å¾µï¼š**
   - è£œå……ç¼ºå¤±çš„ rolling ç‰¹å¾µï¼ˆrolling_mean, rolling_max, rolling_minï¼‰
   - æ·»åŠ  lag ç‰¹å¾µ
   - é”åˆ°èˆ‡ XGBoost ç›¸åŒçš„ç‰¹å¾µè¦†è“‹åº¦

2. **èª¿æ•´æ¶æ§‹ï¼š**
   - å¢åŠ éš±è—å±¤å¤§å°ï¼ˆ32 â†’ 64/128ï¼‰
   - æ·»åŠ æ›´å¤š LSTM å±¤ï¼ˆ1 â†’ 2/3ï¼‰
   - å˜—è©¦ Bidirectional LSTM

3. **å„ªåŒ–è¶…åƒæ•¸ï¼š**
   - èª¿æ•´åºåˆ—é•·åº¦ï¼ˆ30 â†’ 60/90ï¼‰
   - å˜—è©¦ä¸åŒçš„å­¸ç¿’ç‡
   - å¢åŠ  dropout ä»¥é˜²æ­¢éæ“¬åˆ

4. **ç‰¹å¾µå·¥ç¨‹ï¼š**
   - å° LSTM ä½¿ç”¨åƒ¹æ ¼å·®åˆ†è€Œéçµ•å°åƒ¹æ ¼
   - æ·»åŠ æŠ€è¡“æŒ‡æ¨™çš„è¡ç”Ÿç‰¹å¾µ
   - å˜—è©¦å¤šè®Šé‡æ™‚é–“åºåˆ—è¼¸å…¥

## 4. æœ€çµ‚å»ºè­°

**ç•¶å‰æƒ…æ³ä¸‹ï¼Œå»ºè­°ä½¿ç”¨ XGBoost æ¨¡å‹ï¼š**

- é æ¸¬ç²¾åº¦æ›´é«˜
- æ–¹å‘æº–ç¢ºç‡æ›´å¥½
- é©åˆç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²
- è¨“ç·´å’Œæ¨ç†é€Ÿåº¦å¿«

**æœªä¾†å¯ä»¥è€ƒæ…®ï¼š**

1. æ”¹é€² LSTM ç‰¹å¾µå·¥ç¨‹å¾Œé‡æ–°è©•ä¼°
2. å˜—è©¦é›†æˆå­¸ç¿’ï¼ˆXGBoost + LSTMï¼‰
3. æ¢ç´¢å…¶ä»–æ·±åº¦å­¸ç¿’æ¶æ§‹ï¼ˆTransformerã€GRUï¼‰
"""

    # ä¿å­˜å ±å‘Š
    with open(output_dir / 'comparison_report.md', 'w', encoding='utf-8') as f:
        f.write(report)

    logger.info(f"å ±å‘Šå·²ä¿å­˜è‡³ {output_dir / 'comparison_report.md'}")

    return report


def create_comparison_plots(results):
    """å‰µå»ºæ¯”è¼ƒåœ–è¡¨"""
    logger.info("å‰µå»ºæ¯”è¼ƒåœ–è¡¨...")

    output_dir = Path('results/model_comparison')
    output_dir.mkdir(parents=True, exist_ok=True)

    xgb_metrics = results['xgboost']['metrics']
    lstm_metrics = results['lstm']['metrics']
    xgb_pred = results['xgboost']['predictions']
    lstm_pred = results['lstm']['predictions']

    # å‰µå»ºåœ–è¡¨
    fig = plt.figure(figsize=(16, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

    # 1. æŒ‡æ¨™æ¯”è¼ƒæŸ±ç‹€åœ–
    ax1 = fig.add_subplot(gs[0, :])
    metrics = ['RMSE', 'MAE', 'MAPE']
    xgb_values = [xgb_metrics['RMSE'], xgb_metrics['MAE'], xgb_metrics['MAPE']]
    lstm_values = [lstm_metrics['RMSE'], lstm_metrics['MAE'], lstm_metrics['MAPE']]

    x = range(len(metrics))
    width = 0.35

    ax1.bar([i - width/2 for i in x], xgb_values, width, label='XGBoost', alpha=0.8)
    ax1.bar([i + width/2 for i in x], lstm_values, width, label='LSTM', alpha=0.8)
    ax1.set_xlabel('Metrics')
    ax1.set_ylabel('Value')
    ax1.set_title('Model Performance Comparison (Lower is Better)')
    ax1.set_xticks(x)
    ax1.set_xticklabels(metrics)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. RÂ² æ¯”è¼ƒ
    ax2 = fig.add_subplot(gs[1, 0])
    models = ['XGBoost', 'LSTM']
    r2_values = [xgb_metrics['R2'], lstm_metrics['R2']]
    colors = ['#2ecc71', '#3498db']

    ax2.bar(models, r2_values, color=colors, alpha=0.8)
    ax2.set_ylabel('RÂ² Score')
    ax2.set_title('RÂ² Score Comparison (Higher is Better)')
    ax2.set_ylim([0.98, 1.0])
    ax2.grid(True, alpha=0.3, axis='y')

    # åœ¨æŸ±å­ä¸Šæ¨™è¨»æ•¸å€¼
    for i, v in enumerate(r2_values):
        ax2.text(i, v + 0.0001, f'{v:.6f}', ha='center', va='bottom', fontsize=9)

    # 3. æ–¹å‘æº–ç¢ºç‡æ¯”è¼ƒ
    ax3 = fig.add_subplot(gs[1, 1])
    dir_acc = [xgb_metrics['Direction_Accuracy'], lstm_metrics['Direction_Accuracy']]

    ax3.bar(models, dir_acc, color=colors, alpha=0.8)
    ax3.set_ylabel('Direction Accuracy (%)')
    ax3.set_title('Direction Accuracy Comparison')
    ax3.axhline(y=50, color='r', linestyle='--', linewidth=1, label='Random (50%)')
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')

    # åœ¨æŸ±å­ä¸Šæ¨™è¨»æ•¸å€¼
    for i, v in enumerate(dir_acc):
        ax3.text(i, v + 1, f'{v:.2f}%', ha='center', va='bottom', fontsize=9)

    # 4. é æ¸¬èª¤å·®æ¯”è¼ƒ
    ax4 = fig.add_subplot(gs[1, 2])

    # ç¢ºä¿å…©å€‹é æ¸¬çµæœé•·åº¦ä¸€è‡´ï¼Œå–æœ€å°é•·åº¦
    min_len = min(len(xgb_pred), len(lstm_pred))
    xgb_errors = (xgb_pred['actual'][:min_len] - xgb_pred['predicted'][:min_len]).abs()
    lstm_errors = (lstm_pred['actual'][:min_len] - lstm_pred['predicted'][:min_len]).abs()

    ax4.hist(xgb_errors, bins=50, alpha=0.6, label='XGBoost', color='#2ecc71')
    ax4.hist(lstm_errors, bins=50, alpha=0.6, label='LSTM', color='#3498db')
    ax4.set_xlabel('Absolute Error (USDT)')
    ax4.set_ylabel('Frequency')
    ax4.set_title('Error Distribution Comparison')
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    # 5. XGBoost é æ¸¬ vs å¯¦éš›
    ax5 = fig.add_subplot(gs[2, 0])
    ax5.plot(xgb_pred['actual'][:200], label='Actual', linewidth=1.5, alpha=0.8)
    ax5.plot(xgb_pred['predicted'][:200], label='Predicted', linewidth=1.5, alpha=0.8)
    ax5.set_xlabel('Sample')
    ax5.set_ylabel('Price (USDT)')
    ax5.set_title('XGBoost: Actual vs Predicted (First 200 samples)')
    ax5.legend()
    ax5.grid(True, alpha=0.3)

    # 6. LSTM é æ¸¬ vs å¯¦éš›
    ax6 = fig.add_subplot(gs[2, 1])
    ax6.plot(lstm_pred['actual'][:200], label='Actual', linewidth=1.5, alpha=0.8)
    ax6.plot(lstm_pred['predicted'][:200], label='Predicted', linewidth=1.5, alpha=0.8)
    ax6.set_xlabel('Sample')
    ax6.set_ylabel('Price (USDT)')
    ax6.set_title('LSTM: Actual vs Predicted (First 200 samples)')
    ax6.legend()
    ax6.grid(True, alpha=0.3)

    # 7. æ€§èƒ½æ”¹é€²ç©ºé–“
    ax7 = fig.add_subplot(gs[2, 2])
    improvement = {
        'RMSE': (lstm_metrics['RMSE'] - xgb_metrics['RMSE']) / xgb_metrics['RMSE'] * 100,
        'MAE': (lstm_metrics['MAE'] - xgb_metrics['MAE']) / xgb_metrics['MAE'] * 100,
        'MAPE': (lstm_metrics['MAPE'] - xgb_metrics['MAPE']) / xgb_metrics['MAPE'] * 100,
    }

    metrics_names = list(improvement.keys())
    improvement_values = list(improvement.values())

    colors_bar = ['#e74c3c' if v > 0 else '#2ecc71' for v in improvement_values]
    ax7.barh(metrics_names, improvement_values, color=colors_bar, alpha=0.8)
    ax7.set_xlabel('Improvement (%)')
    ax7.set_title('LSTM vs XGBoost Performance Gap\n(Negative = XGBoost Better)')
    ax7.axvline(x=0, color='black', linewidth=0.8)
    ax7.grid(True, alpha=0.3, axis='x')

    # åœ¨æŸ±å­ä¸Šæ¨™è¨»æ•¸å€¼
    for i, v in enumerate(improvement_values):
        ax7.text(v, i, f'{v:+.1f}%', ha='left' if v > 0 else 'right', va='center', fontsize=9)

    plt.savefig(output_dir / 'model_comparison.png', dpi=150, bbox_inches='tight')
    logger.info(f"åœ–è¡¨å·²ä¿å­˜è‡³ {output_dir / 'model_comparison.png'}")


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=" * 80)
    logger.info("é–‹å§‹ç”Ÿæˆæ¨¡å‹æ¯”è¼ƒå ±å‘Š")
    logger.info("=" * 80)

    # è¼‰å…¥çµæœ
    results = load_results()

    # å‰µå»ºæ¯”è¼ƒå ±å‘Š
    report = create_comparison_report(results)

    # å‰µå»ºæ¯”è¼ƒåœ–è¡¨
    create_comparison_plots(results)

    logger.info("=" * 80)
    logger.info("æ¨¡å‹æ¯”è¼ƒå ±å‘Šç”Ÿæˆå®Œæˆï¼")
    logger.info("=" * 80)

    # æ‰“å°ç°¡è¦çµè«–
    print("\n" + "=" * 80)
    print("ä¸»è¦çµè«–:")
    print("=" * 80)
    print(f"XGBoost RMSE: {results['xgboost']['metrics']['RMSE']:.2f} USDT")
    print(f"LSTM RMSE: {results['lstm']['metrics']['RMSE']:.2f} USDT")
    print(f"XGBoost å„ªæ–¼ LSTM: {results['lstm']['metrics']['RMSE'] / results['xgboost']['metrics']['RMSE']:.2f}x")
    print()
    print(f"XGBoost æ–¹å‘æº–ç¢ºç‡: {results['xgboost']['metrics']['Direction_Accuracy']:.2f}%")
    print(f"LSTM æ–¹å‘æº–ç¢ºç‡: {results['lstm']['metrics']['Direction_Accuracy']:.2f}%")
    print()
    print("å»ºè­°: ç•¶å‰æƒ…æ³ä¸‹ä½¿ç”¨ XGBoost æ¨¡å‹")
    print("=" * 80)


if __name__ == '__main__':
    main()
