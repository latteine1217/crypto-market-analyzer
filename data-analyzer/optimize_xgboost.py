"""
XGBoost è¶…åƒæ•¸å„ªåŒ–
ä½¿ç”¨ç¶²æ ¼æœç´¢å’Œäº¤å‰é©—è­‰å°‹æ‰¾æœ€ä½³è¶…åƒæ•¸
"""

import numpy as np
import pandas as pd
import psycopg2
import logging
import json
import joblib
from pathlib import Path
from datetime import datetime
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_data_from_db():
    """å¾è³‡æ–™åº«è¼‰å…¥æ•¸æ“š"""
    logger.info("å¾è³‡æ–™åº«è¼‰å…¥æ•¸æ“š...")

    conn = psycopg2.connect(
        host='localhost',
        database='crypto_db',
        user='crypto',
        password='crypto_pass'
    )

    query = """
        SELECT o.open_time, o.open, o.high, o.low, o.close, o.volume, o.quote_volume
        FROM ohlcv o
        JOIN markets m ON o.market_id = m.id
        JOIN exchanges e ON m.exchange_id = e.id
        WHERE e.name = 'bybit'
            AND m.symbol = 'BTC/USDT'
            AND o.timeframe = '1h'
        ORDER BY o.open_time
    """

    df = pd.read_sql_query(query, conn)
    conn.close()

    logger.info(f"è¼‰å…¥ {len(df)} ç­†æ•¸æ“š")
    logger.info(f"æ™‚é–“ç¯„åœ: {df['open_time'].min()} ~ {df['open_time'].max()}")

    return df


def create_features(df):
    """å‰µå»ºå®Œæ•´ç‰¹å¾µé›†"""
    logger.info("å‰µå»ºç‰¹å¾µ...")

    from src.features.technical_indicators import TechnicalIndicators
    from src.features.price_features import PriceFeatures
    from src.features.volume_features import VolumeFeatures

    # æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ
    tech_indicators = TechnicalIndicators()
    price_features = PriceFeatures()
    volume_features = VolumeFeatures()

    tech_feat = tech_indicators.calculate_all(df)
    price_feat = price_features.calculate_all(df)
    volume_feat = volume_features.calculate_all(df)

    # ç§»é™¤é‡è¤‡çš„ OHLCV åˆ—
    tech_cols = [col for col in tech_feat.columns
                if col not in ['open', 'high', 'low', 'close', 'volume', 'quote_volume']]
    price_cols = [col for col in price_feat.columns
                 if col not in ['open', 'high', 'low', 'close', 'volume', 'quote_volume']]
    volume_cols = [col for col in volume_feat.columns
                  if col not in ['open', 'high', 'low', 'close', 'volume', 'quote_volume']]

    # åˆä½µç‰¹å¾µ
    features = pd.concat([
        tech_feat[tech_cols],
        price_feat[price_cols],
        volume_feat[volume_cols]
    ], axis=1)

    # å‰å‘å¡«å……ä¸¦åˆªé™¤ NaN
    features = features.ffill().dropna()

    logger.info(f"ç‰¹å¾µç¸½æ•¸: {features.shape[1]}")

    return features


def optimize_hyperparameters(X_train, y_train):
    """è¶…åƒæ•¸ç¶²æ ¼æœç´¢"""
    logger.info("é–‹å§‹è¶…åƒæ•¸å„ªåŒ–...")

    # å®šç¾©åƒæ•¸ç¶²æ ¼
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [6, 8, 10],
        'learning_rate': [0.01, 0.05, 0.1],
        'subsample': [0.8, 0.9, 1.0],
        'colsample_bytree': [0.8, 0.9, 1.0],
        'min_child_weight': [1, 3, 5]
    }

    logger.info(f"åƒæ•¸ç¶²æ ¼å¤§å°: {np.prod([len(v) for v in param_grid.values()])} çµ„åˆ")

    # ä½¿ç”¨æ™‚é–“åºåˆ—äº¤å‰é©—è­‰
    tscv = TimeSeriesSplit(n_splits=3)

    # å‰µå»º XGBoost æ¨¡å‹
    xgb_model = xgb.XGBRegressor(
        objective='reg:squarederror',
        random_state=42,
        n_jobs=-1
    )

    # ç¶²æ ¼æœç´¢
    grid_search = GridSearchCV(
        estimator=xgb_model,
        param_grid=param_grid,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=2
    )

    logger.info("é–‹å§‹ç¶²æ ¼æœç´¢...")
    grid_search.fit(X_train, y_train)

    logger.info(f"æœ€ä½³åƒæ•¸: {grid_search.best_params_}")
    logger.info(f"æœ€ä½³åˆ†æ•¸ (è²  MSE): {grid_search.best_score_:.4f}")

    return grid_search.best_estimator_, grid_search.best_params_, grid_search.cv_results_


def evaluate_model(model, X_test, y_test):
    """è©•ä¼°æ¨¡å‹"""
    logger.info("è©•ä¼°å„ªåŒ–å¾Œçš„æ¨¡å‹...")

    y_pred = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

    # æ–¹å‘æº–ç¢ºç‡
    y_test_direction = np.diff(y_test) > 0
    y_pred_direction = np.diff(y_pred) > 0
    direction_accuracy = np.mean(y_test_direction == y_pred_direction) * 100

    metrics = {
        'RMSE': rmse,
        'MAE': mae,
        'R2': r2,
        'MAPE': mape,
        'Direction_Accuracy': direction_accuracy
    }

    logger.info("æ¸¬è©¦é›†æ€§èƒ½:")
    for metric, value in metrics.items():
        logger.info(f"  {metric}: {value:.4f}")

    return metrics, y_pred


def plot_optimization_results(cv_results, output_dir):
    """ç¹ªè£½å„ªåŒ–çµæœ"""
    logger.info("ç¹ªè£½å„ªåŒ–çµæœ...")

    results_df = pd.DataFrame(cv_results)

    # å‰µå»ºåœ–è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # 1. åƒæ•¸é‡è¦æ€§åˆ†æ - n_estimators
    ax1 = axes[0, 0]
    param_scores = results_df.groupby('param_n_estimators')['mean_test_score'].mean()
    ax1.plot(param_scores.index.astype(int), -param_scores.values, marker='o', linewidth=2)
    ax1.set_xlabel('n_estimators')
    ax1.set_ylabel('Mean CV Score (RMSE)')
    ax1.set_title('Effect of n_estimators on Performance')
    ax1.grid(True, alpha=0.3)

    # 2. åƒæ•¸é‡è¦æ€§åˆ†æ - max_depth
    ax2 = axes[0, 1]
    param_scores = results_df.groupby('param_max_depth')['mean_test_score'].mean()
    ax2.plot(param_scores.index.astype(int), -param_scores.values, marker='o', linewidth=2)
    ax2.set_xlabel('max_depth')
    ax2.set_ylabel('Mean CV Score (RMSE)')
    ax2.set_title('Effect of max_depth on Performance')
    ax2.grid(True, alpha=0.3)

    # 3. åƒæ•¸é‡è¦æ€§åˆ†æ - learning_rate
    ax3 = axes[1, 0]
    param_scores = results_df.groupby('param_learning_rate')['mean_test_score'].mean()
    ax3.plot(param_scores.index.astype(float), -param_scores.values, marker='o', linewidth=2)
    ax3.set_xlabel('learning_rate')
    ax3.set_ylabel('Mean CV Score (RMSE)')
    ax3.set_title('Effect of learning_rate on Performance')
    ax3.grid(True, alpha=0.3)

    # 4. Top 10 åƒæ•¸çµ„åˆ
    ax4 = axes[1, 1]
    top_10 = results_df.nsmallest(10, 'rank_test_score')
    top_10_labels = [f"Config {i+1}" for i in range(len(top_10))]
    ax4.barh(top_10_labels, -top_10['mean_test_score'].values, alpha=0.8)
    ax4.set_xlabel('Mean CV Score (RMSE)')
    ax4.set_title('Top 10 Parameter Configurations')
    ax4.grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    plt.savefig(output_dir / 'optimization_results.png', dpi=150, bbox_inches='tight')
    logger.info(f"å„ªåŒ–çµæœåœ–å·²ä¿å­˜è‡³ {output_dir / 'optimization_results.png'}")


def save_results(model, best_params, metrics, y_pred, y_test, cv_results, feature_names):
    """ä¿å­˜çµæœ"""
    logger.info("ä¿å­˜å„ªåŒ–çµæœ...")

    output_dir = Path('results/xgboost_optimized_btc_1h')
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜æ¨¡å‹
    model_data = {
        'model': model,
        'best_params': best_params,
        'feature_names': feature_names
    }
    joblib.dump(model_data, output_dir / 'xgboost_optimized_model.joblib')

    # ä¿å­˜æŒ‡æ¨™
    with open(output_dir / 'metrics.json', 'w') as f:
        json.dump(metrics, f, indent=2)

    # ä¿å­˜æœ€ä½³åƒæ•¸
    with open(output_dir / 'best_params.json', 'w') as f:
        json.dump(best_params, f, indent=2)

    # ä¿å­˜ CV çµæœ
    cv_results_df = pd.DataFrame(cv_results)
    cv_results_df.to_csv(output_dir / 'cv_results.csv', index=False)

    # ä¿å­˜é æ¸¬çµæœ
    results_df = pd.DataFrame({
        'actual': y_test,
        'predicted': y_pred,
        'error': y_test - y_pred
    })
    results_df.to_csv(output_dir / 'predictions.csv', index=False)

    # ä¿å­˜ç‰¹å¾µé‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    feature_importance.to_csv(output_dir / 'feature_importance.csv', index=False)

    # ç¹ªè£½å„ªåŒ–çµæœ
    plot_optimization_results(cv_results, output_dir)

    # ç¹ªè£½è©•ä¼°åœ–è¡¨
    plot_evaluation(y_test, y_pred, metrics, output_dir)

    # ç”Ÿæˆå ±å‘Š
    generate_report(best_params, metrics, feature_importance, output_dir)

    logger.info(f"çµæœå·²ä¿å­˜è‡³ {output_dir}")


def plot_evaluation(y_test, y_pred, metrics, output_dir):
    """ç¹ªè£½è©•ä¼°åœ–è¡¨"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # 1. å¯¦éš› vs é æ¸¬
    axes[0, 0].plot(y_test[:300], label='Actual', linewidth=1.5, alpha=0.8)
    axes[0, 0].plot(y_pred[:300], label='Predicted', linewidth=1.5, alpha=0.8)
    axes[0, 0].set_title('Actual vs Predicted (First 300 samples)')
    axes[0, 0].set_xlabel('Sample')
    axes[0, 0].set_ylabel('Price (USDT)')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # 2. èª¤å·®åˆ†å¸ƒ
    errors = y_test - y_pred
    axes[0, 1].hist(errors, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
    axes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=1.5)
    axes[0, 1].set_title(f'Error Distribution\nMean: {errors.mean():.2f}, Std: {errors.std():.2f}')
    axes[0, 1].set_xlabel('Error (USDT)')
    axes[0, 1].set_ylabel('Frequency')
    axes[0, 1].grid(True, alpha=0.3)

    # 3. æ•£é»åœ–
    axes[1, 0].scatter(y_test, y_pred, alpha=0.3, s=10)
    axes[1, 0].plot([y_test.min(), y_test.max()],
                    [y_test.min(), y_test.max()],
                    'r--', linewidth=2, label='Perfect Prediction')
    axes[1, 0].set_title(f'Predicted vs Actual\nRÂ² = {metrics["R2"]:.6f}')
    axes[1, 0].set_xlabel('Actual Price (USDT)')
    axes[1, 0].set_ylabel('Predicted Price (USDT)')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # 4. æ€§èƒ½æŒ‡æ¨™è¡¨
    ax4 = axes[1, 1]
    ax4.axis('off')

    metrics_text = f"""
    Performance Metrics
    {'='*40}

    RMSE:              {metrics['RMSE']:.2f} USDT
    MAE:               {metrics['MAE']:.2f} USDT
    RÂ²:                {metrics['R2']:.6f}
    MAPE:              {metrics['MAPE']:.3f}%
    Direction Accuracy: {metrics['Direction_Accuracy']:.2f}%
    """

    ax4.text(0.1, 0.5, metrics_text, fontsize=12, family='monospace',
             verticalalignment='center')

    plt.tight_layout()
    plt.savefig(output_dir / 'evaluation.png', dpi=150, bbox_inches='tight')


def generate_report(best_params, metrics, feature_importance, output_dir):
    """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
    report = f"""# XGBoost è¶…åƒæ•¸å„ªåŒ–å ±å‘Š

**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## 1. æœ€ä½³è¶…åƒæ•¸

```python
{json.dumps(best_params, indent=2)}
```

## 2. æ€§èƒ½æŒ‡æ¨™

| æŒ‡æ¨™ | æ•¸å€¼ | èªªæ˜ |
|------|------|------|
| RMSE | {metrics['RMSE']:.2f} | å‡æ–¹æ ¹èª¤å·® |
| MAE | {metrics['MAE']:.2f} | å¹³å‡çµ•å°èª¤å·® |
| RÂ² | {metrics['R2']:.6f} | æ±ºå®šä¿‚æ•¸ |
| MAPE | {metrics['MAPE']:.3f}% | å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·® |
| æ–¹å‘æº–ç¢ºç‡ | {metrics['Direction_Accuracy']:.2f}% | æ¼²è·Œæ–¹å‘é æ¸¬æº–ç¢ºç‡ |

## 3. å‰ 20 å€‹é‡è¦ç‰¹å¾µ

| æ’å | ç‰¹å¾µåç¨± | é‡è¦æ€§ |
|------|----------|--------|
{chr(10).join([f"| {i+1} | {row['feature']} | {row['importance']:.2f} |" for i, row in feature_importance.head(20).iterrows()])}

## 4. å„ªåŒ–ç¸½çµ

### âœ… å„ªåŒ–æˆæœ

- ä½¿ç”¨æ™‚é–“åºåˆ—äº¤å‰é©—è­‰ï¼ˆ3-foldï¼‰
- ç¶²æ ¼æœç´¢æ¶µè“‹ 6 å€‹é—œéµè¶…åƒæ•¸
- ç¢ºä¿æ¨¡å‹åœ¨ä¸åŒæ™‚é–“æ®µçš„ç©©å®šæ€§

### ğŸ“Š èˆ‡åŸºç·šæ¨¡å‹æ¯”è¼ƒ

æŸ¥çœ‹ `results/final_model_comparison/` ç›®éŒ„ä¸­çš„å®Œæ•´æ¯”è¼ƒå ±å‘Šã€‚

### ğŸš€ ä¸‹ä¸€æ­¥

1. ä½¿ç”¨å„ªåŒ–å¾Œçš„æ¨¡å‹é€²è¡Œç­–ç•¥å›æ¸¬
2. è©•ä¼°çœŸå¯¦äº¤æ˜“ç’°å¢ƒä¸‹çš„æ€§èƒ½
3. è€ƒæ…®é›†æˆå­¸ç¿’é€²ä¸€æ­¥æå‡
"""

    with open(output_dir / 'optimization_report.md', 'w', encoding='utf-8') as f:
        f.write(report)


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=" * 80)
    logger.info("é–‹å§‹ XGBoost è¶…åƒæ•¸å„ªåŒ–")
    logger.info("=" * 80)

    # 1. è¼‰å…¥æ•¸æ“š
    df = load_data_from_db()

    # 2. å‰µå»ºç‰¹å¾µ
    features = create_features(df)

    # ç¢ºä¿ç´¢å¼•å°é½Š
    df = df.loc[features.index]
    target = df['close'].values

    logger.info(f"ç‰¹å¾µå½¢ç‹€: {features.shape}")
    logger.info(f"ç›®æ¨™å½¢ç‹€: {target.shape}")

    # 3. åˆ†å‰²æ•¸æ“šï¼ˆ80/20ï¼‰
    split_idx = int(len(features) * 0.8)
    X_train = features.iloc[:split_idx].values
    y_train = target[:split_idx]
    X_test = features.iloc[split_idx:].values
    y_test = target[split_idx:]

    logger.info(f"è¨“ç·´é›†: {X_train.shape}, æ¸¬è©¦é›†: {X_test.shape}")

    # 4. è¶…åƒæ•¸å„ªåŒ–
    best_model, best_params, cv_results = optimize_hyperparameters(X_train, y_train)

    # 5. è©•ä¼°æ¨¡å‹
    metrics, y_pred = evaluate_model(best_model, X_test, y_test)

    # 6. ä¿å­˜çµæœ
    save_results(best_model, best_params, metrics, y_pred, y_test, cv_results, features.columns.tolist())

    logger.info("=" * 80)
    logger.info("XGBoost è¶…åƒæ•¸å„ªåŒ–å®Œæˆï¼")
    logger.info("=" * 80)
    logger.info(f"\næœ€ä½³åƒæ•¸: {best_params}")
    logger.info(f"\næ€§èƒ½ç¸½çµ:")
    logger.info(f"  RMSE: {metrics['RMSE']:.2f} USDT")
    logger.info(f"  RÂ²: {metrics['R2']:.6f}")
    logger.info(f"  æ–¹å‘æº–ç¢ºç‡: {metrics['Direction_Accuracy']:.2f}%")


if __name__ == '__main__':
    main()
