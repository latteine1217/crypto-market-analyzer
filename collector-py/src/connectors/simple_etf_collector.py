"""
ç°¡åŒ–ç‰ˆ ETF Collector - ä½¿ç”¨å…¬é–‹ CSV æˆ–æ‰‹å‹•æ•¸æ“š

è€ƒæ…®åˆ° Farside Investors æœ‰åš´æ ¼çš„ Cloudflare ä¿è­·ï¼Œ
æœ¬å¯¦ä½œæä¾›ä¸‰ç¨®æ–¹æ¡ˆï¼š

æ–¹æ¡ˆ 1: æ‰‹å‹• CSV åŒ¯å…¥ï¼ˆæ¨è–¦ï¼Œæœ€ç©©å®šï¼‰
- æ¯æ—¥å¾ Farside æ‰‹å‹•ä¸‹è¼‰ CSV
- æ”¾å…¥ `data/etf_flows/` ç›®éŒ„
- è‡ªå‹•è§£æä¸¦åŒ¯å…¥è³‡æ–™åº«

æ–¹æ¡ˆ 2: ä½¿ç”¨ GitHub é–‹æºæ•¸æ“šé›†
- ç¤¾ç¾¤ç¶­è­·çš„ ETF è³‡æ–™åº«ï¼ˆä¾‹å¦‚ï¼šhttps://github.com/bitcoin-etf-trackerï¼‰
- æ¯æ—¥è‡ªå‹•åŒæ­¥

æ–¹æ¡ˆ 3: ä½¿ç”¨ Selenium/Playwrightï¼ˆè¤‡é›œä½†è‡ªå‹•åŒ–ï¼‰
- éœ€å®‰è£ç€è¦½å™¨é©…å‹•
- å¯ç¹é Cloudflare
- ç¶­è­·æˆæœ¬è¼ƒé«˜

ç•¶å‰å¯¦ä½œï¼šæ–¹æ¡ˆ 1ï¼ˆCSV åŒ¯å…¥ï¼‰
"""

from typing import List, Dict
from datetime import date, datetime
from loguru import logger
import pandas as pd
import glob
import os


class SimpleETFCollector:
    """
    ç°¡åŒ–ç‰ˆ ETF Collector
    
    ä½¿ç”¨ CSV æª”æ¡ˆåŒ¯å…¥ï¼ˆæ‰‹å‹•æˆ–è‡ªå‹•ä¸‹è¼‰ï¼‰
    
    CSV æ ¼å¼ç¯„ä¾‹ï¼š
    ```
    Date,Product,Issuer,Asset,NetFlow_USD,AUM_USD
    2026-01-15,IBIT,BlackRock,BTC,125000000,5000000000
    2026-01-15,GBTC,Grayscale,BTC,-80000000,18000000000
    ```
    """
    
    def __init__(self, csv_directory: str = "data/etf_flows"):
        self.csv_directory = csv_directory
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(csv_directory, exist_ok=True)
        
        logger.info(f"ETF Collector initialized. CSV directory: {csv_directory}")
        logger.info(f"ğŸ’¡ To add data: Place CSV files in {csv_directory}/")
    
    def load_csv_files(self) -> List[Dict]:
        """è¼‰å…¥æ‰€æœ‰ CSV æª”æ¡ˆ"""
        csv_pattern = os.path.join(self.csv_directory, "*.csv")
        csv_files = glob.glob(csv_pattern)
        
        if not csv_files:
            logger.warning(f"No CSV files found in {self.csv_directory}")
            logger.info("ğŸ’¡ Please download ETF data from https://farside.co.uk/ and save as CSV")
            return []
        
        logger.info(f"Found {len(csv_files)} CSV file(s)")
        
        all_data = []
        
        for csv_file in csv_files:
            try:
                logger.info(f"Loading {os.path.basename(csv_file)}...")
                df = pd.read_csv(csv_file)
                
                # æ¨™æº–åŒ–æ¬„ä½åç¨±
                df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]
                
                # è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨
                for _, row in df.iterrows():
                    record = self._parse_csv_row(row)
                    if record:
                        all_data.append(record)
                
                logger.info(f"  âœ… Loaded {len(df)} records")
                
            except Exception as e:
                logger.error(f"  âŒ Failed to load {csv_file}: {e}")
                continue
        
        logger.info(f"Total records loaded: {len(all_data)}")
        return all_data
    
    def _parse_csv_row(self, row) -> Dict:
        """è§£æ CSV è¡Œ"""
        try:
            # è§£ææ—¥æœŸï¼ˆæ”¯æ´å¤šç¨®æ ¼å¼ï¼‰
            date_value = row.get('date') or row.get('flow_date')
            if pd.isna(date_value):
                return None
            
            if isinstance(date_value, str):
                parsed_date = pd.to_datetime(date_value).date()
            else:
                parsed_date = date_value
            
            # è§£æç”¢å“è³‡è¨Š
            product_code = str(row.get('product') or row.get('product_code', 'UNKNOWN'))
            issuer = str(row.get('issuer', 'Unknown'))
            asset_type = str(row.get('asset') or row.get('asset_type', 'BTC')).upper()
            
            # è§£ææµå‘ï¼ˆå¯èƒ½åŒ…å« $ ç¬¦è™Ÿæˆ–é€—è™Ÿï¼‰
            net_flow_raw = row.get('netflow_usd') or row.get('net_flow') or row.get('flow')
            if pd.isna(net_flow_raw):
                net_flow_usd = 0.0
            else:
                net_flow_usd = float(str(net_flow_raw).replace('$', '').replace(',', ''))
            
            # è§£æ AUMï¼ˆå¯é¸ï¼‰
            aum_raw = row.get('aum_usd') or row.get('aum')
            if pd.isna(aum_raw):
                aum_usd = None
            else:
                aum_usd = float(str(aum_raw).replace('$', '').replace(',', ''))
            
            return {
                'date': parsed_date,
                'product_code': product_code,
                'product_name': product_code,  # CSV é€šå¸¸ä¸åŒ…å«å®Œæ•´åç¨±
                'issuer': issuer,
                'asset_type': asset_type,
                'net_flow_usd': net_flow_usd,
                'total_aum_usd': aum_usd
            }
            
        except Exception as e:
            logger.debug(f"Failed to parse row: {e}")
            return None
    
    def fetch_all_etf_flows(self, days: int = 7) -> List[Dict]:
        """æŠ“å–æ‰€æœ‰ ETF æµå‘ï¼ˆå¾ CSV æª”æ¡ˆï¼‰"""
        all_data = self.load_csv_files()
        
        if not all_data:
            logger.warning("âš ï¸  No ETF CSV data available. Returning empty result.")
            return []
        
        # ç¯©é¸æœ€è¿‘ N å¤©
        cutoff_date = date.today() - pd.Timedelta(days=days)
        filtered_data = [d for d in all_data if d['date'] >= cutoff_date]
        
        logger.info(f"Filtered to {len(filtered_data)} records (last {days} days)")
        return filtered_data
    
    
    def run_collection(self, db_loader, days: int = 7) -> int:
        """åŸ·è¡Œæ”¶é›†ä»»å‹™"""
        logger.info("ğŸš€ Starting Simple ETF collection...")
        
        data = self.fetch_all_etf_flows(days)
        
        if not data:
            logger.warning("No data to insert")
            return 0
        
        inserted_count = db_loader.insert_etf_flows_batch(data)
        
        logger.info(f"âœ… ETF collection complete: {inserted_count} records inserted")
        return inserted_count
    
    def create_sample_csv(self):
        """å»ºç«‹ç¯„ä¾‹ CSV æª”æ¡ˆï¼ˆä¾›åƒè€ƒï¼‰"""
        sample_file = os.path.join(self.csv_directory, "sample_etf_data.csv")
        
        sample_data = {
            'Date': ['2026-01-15', '2026-01-15', '2026-01-14'],
            'Product': ['IBIT', 'GBTC', 'IBIT'],
            'Issuer': ['BlackRock', 'Grayscale', 'BlackRock'],
            'Asset': ['BTC', 'BTC', 'BTC'],
            'NetFlow_USD': [125000000, -80000000, 95000000],
            'AUM_USD': [5000000000, 18000000000, 4900000000]
        }
        
        df = pd.DataFrame(sample_data)
        df.to_csv(sample_file, index=False)
        
        logger.info(f"âœ… Sample CSV created: {sample_file}")
        logger.info(f"ğŸ’¡ Use this format for your own data")
